{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import easyocr\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "from tqdm import tqdm \n",
    "class TextFeatureExtractor:\n",
    "    def __init__(self, csv_file, dataset_folder):\n",
    "        self.csv_file = csv_file\n",
    "        self.dataset_folder = dataset_folder\n",
    "        self.batch_size = 2000\n",
    "        self.reader = easyocr.Reader(['en'], gpu=torch.cuda.is_available())\n",
    "        self.pattern = r'(\\d*\\.?\\d+)(?:\\s*-\\s*(\\d*\\.?\\d+))?\\s*(centimetre|centimeter|centimeters|cm|foot|feet|ft|inch|inches|in|\"|metre|meter|meters|m|mtr|millimetre|millimeter|millimeters|mm|yard|yards|yd|gram|grams|g|grm|kilogram|kilograms|kg|kgs|microgram|micrograms|mcg|µg|milligram|milligrams|mg|ounce|ounces|oz|pound|pounds|lb|lbs|ton|tons|T|tn|kilovolt|kilovolts|kv|kV|millivolt|millivolts|mv|mV|volt|volts|v|V|kilowatt|kilowatts|kw|kW|watt|watts|w|W|centilitre|centilitres|cl|cL|cubic foot|cubic feet|ft³|ft\\^3|cu ft|cubic inch|cubic inches|in³|in\\^3|cu in|cup|cups|c\\.|decilitre|decilitres|dl|dL|fluid ounce|fluid ounces|fl oz|fl\\. oz\\.|gallon|gallons|gal|imperial gallon|imperial gallons|imp gal|litre|litres|liter|liters|l|L|ltr|microlitre|microlitres|µl|mcL|millilitre|millilitres|ml|mL|pint|pints|pt|quart|quarts|qt)'\n",
    "\n",
    "        self.entity_unit_map = {        'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "        'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "        'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "        'item_weight': {'gram',\n",
    "        'kilogram',\n",
    "        'microgram',\n",
    "        'milligram',\n",
    "        'ounce',\n",
    "        'pound',\n",
    "        'ton'},\n",
    "        'maximum_weight_recommendation': {'gram',\n",
    "        'kilogram',\n",
    "        'microgram',\n",
    "        'milligram',\n",
    "        'ounce',\n",
    "        'pound',\n",
    "        'ton'},\n",
    "        'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
    "        'wattage': {'kilowatt', 'watt'},\n",
    "        'item_volume': {'centilitre',\n",
    "        'cubic foot',\n",
    "        'cubic inch',\n",
    "        'cup',\n",
    "        'decilitre',\n",
    "        'fluid ounce',\n",
    "        'gallon',\n",
    "        'imperial gallon',\n",
    "        'litre',\n",
    "        'microlitre',\n",
    "        'millilitre',\n",
    "        'pint',\n",
    "        'quart'}}\n",
    "\n",
    "        self.normalization = {\n",
    "            'length': {\n",
    "                'centimetre': 'centimetre', 'centimeter': 'centimetre', 'centimeters': 'centimetre', 'cm': 'centimetre',\n",
    "                'foot': 'foot', 'feet': 'foot', 'ft': 'foot', 'inch': 'inch', 'inches': 'inch', 'in': 'inch', '\"': 'inch',\n",
    "                'metre': 'metre', 'meter': 'metre', 'meters': 'metre', 'm': 'metre', 'millimetre': 'millimetre', 'mm': 'millimetre',\n",
    "                'yard': 'yard', 'yd': 'yard'\n",
    "            },\n",
    "            'weight': {\n",
    "                'gram': 'gram', 'grams': 'gram', 'g': 'gram',\n",
    "                'kilogram': 'kilogram', 'kg': 'kilogram', 'microgram': 'microgram', 'mcg': 'microgram',\n",
    "                'milligram': 'milligram', 'mg': 'milligram',\n",
    "                'ounce': 'ounce', 'oz': 'ounce', 'pound': 'pound', 'lb': 'pound', 'ton': 'ton'\n",
    "            },\n",
    "            'voltage': {\n",
    "                'kilovolt': 'kilovolt', 'kv': 'kilovolt', 'volt': 'volt', 'v': 'volt', \n",
    "            },\n",
    "            'wattage': {\n",
    "                'kilowatt': 'kilowatt', 'kw': 'kilowatt', 'watt': 'watt', 'w': 'watt'\n",
    "            },\n",
    "            'volume': {\n",
    "                'litre': 'litre', 'liter': 'litre', 'ml': 'millilitre', 'fluid ounce': 'fluid ounce', 'fl oz': 'fluid ounce',\n",
    "                'gallon': 'gallon', 'quart': 'quart', 'pint': 'pint', 'cup':'cup'}}\n",
    "\n",
    "    def process_csv_in_batches(self):\n",
    "            output_file = 'test_out1.csv'\n",
    "\n",
    "            with open(self.csv_file, mode='r') as file, open(output_file, mode='w', newline='') as outfile:\n",
    "                csv_reader = list(csv.reader(file)) \n",
    "                csv_writer = csv.writer(outfile)\n",
    "\n",
    "                # Write header to output.csv\n",
    "                csv_writer.writerow(['index', 'prediction'])\n",
    "\n",
    "                csv_reader = csv_reader[1:]  # Skip header row\n",
    "                total_rows = len(csv_reader)\n",
    "                processed_images = set()\n",
    "\n",
    "                # Process data in batches\n",
    "                for batch_start in tqdm(range(0, total_rows, self.batch_size), desc=\"Processing Batches\"):\n",
    "                    batch_end = min(batch_start + self.batch_size, total_rows)\n",
    "                    batch_rows = csv_reader[batch_start:batch_end]\n",
    "\n",
    "                    # Process each image in the batch\n",
    "                    for idx, row in enumerate(batch_rows, start=batch_start):\n",
    "                        image_link = row[1]\n",
    "                        image_name = image_link.split(\"/\")[-1]\n",
    "                        entity_name = row[3]\n",
    "                       \n",
    "\n",
    "                        processed_images.add(image_name)\n",
    "                        image_path = os.path.join(self.dataset_folder, image_name)\n",
    "\n",
    "                        if not os.path.exists(image_path):\n",
    "                            csv_writer.writerow([idx,\"\"])\n",
    "                            continue\n",
    "                        value1 = \"\"\n",
    "                        try:\n",
    "                            result = self.reader.readtext(image_path, detail=0)\n",
    "                            extracted_text = ' '.join(result)\n",
    "                            features = self.extract_features(extracted_text)\n",
    "                            normalized_features = self.normalize_units(row[3], features)\n",
    "                            if normalized_features:\n",
    "                              for value, unit in normalized_features:\n",
    "                               if unit in self.entity_unit_map.get(entity_name, set()):\n",
    "                                value1 = value + \" \" + unit\n",
    "                               else:\n",
    "                                value1 = \"\"\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing image {image_name} at index {idx} : {e}\")\n",
    "                            value1 = \"\"    \n",
    "\n",
    "                        csv_writer.writerow([idx, value1])\n",
    "                    \n",
    "                    outfile.flush()\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "\n",
    "    def extract_features(self, text):\n",
    "        matches = re.findall(self.pattern, text)\n",
    "        return matches if matches else []\n",
    "\n",
    "    def normalize_units(self, entity_name, features):\n",
    "        entity_type = self.get_entity_type(entity_name)  # Find the entity type for the current entity\n",
    "        normalized = []\n",
    "        \n",
    "        if entity_type in self.normalization:\n",
    "            normalization_dict = self.normalization[entity_type]  # Fetch normalization for the specific entity type\n",
    "            for feature in features:\n",
    "                if len(feature) == 3:\n",
    "                    value, __, unit = feature\n",
    "                elif len(feature) == 2:\n",
    "                    value, unit = feature\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                normalized_unit = normalization_dict.get(unit, unit)  # Lookup unit only in the relevant entity type\n",
    "                normalized.append((value, normalized_unit))\n",
    "        \n",
    "        return normalized\n",
    "\n",
    "    def get_entity_type(self, entity_name):\n",
    "        # This function maps entity names to entity types, improving performance by narrowing the normalization search\n",
    "        if entity_name in {'width', 'depth', 'height'}:\n",
    "            return 'length'\n",
    "        elif entity_name in {'item_weight', 'maximum_weight_recommendation'}:\n",
    "            return 'weight'\n",
    "        elif entity_name == 'voltage':\n",
    "            return 'voltage'\n",
    "        elif entity_name == 'wattage':\n",
    "            return 'wattage'\n",
    "        elif entity_name == 'item_volume':\n",
    "            return 'volume'\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def filter_features(self, entity_name, features):\n",
    "        if entity_name in self.entity_unit_map:\n",
    "            allowed_units = self.entity_unit_map[entity_name]\n",
    "            return [(value, unit) for value, unit in features if unit in allowed_units]\n",
    "        return []\n",
    "csv_file_path = 'dataset/test.csv'  # Replace with the path to your CSV file\n",
    "dataset_folder_path = 'test_images'  # Replace with the path to your image folder\n",
    "\n",
    "# Create an instance of TextFeatureExtractor\n",
    "extractor = TextFeatureExtractor(csv_file=csv_file_path, dataset_folder=dataset_folder_path)\n",
    "\n",
    "# Process the CSV file to extract and validate features from the images\n",
    "extractor.process_csv_in_batches()      \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
